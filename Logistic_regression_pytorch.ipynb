{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_regression_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPvt9D9oTeZhF2oqV4dZg8S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yugpsyfer/Playing_with_PyTorch/blob/main/Logistic_regression_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ONLY REQUIRED ONCE"
      ],
      "metadata": {
        "id": "QT5p_3uu51xW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8WUuCPcm5Jv"
      },
      "outputs": [],
      "source": [
        "# !pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "PabXwXxk23q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import  torch.nn.functional as F"
      ],
      "metadata": {
        "id": "sESFkLHUdYn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***root*** stands for the root folder where you would want to save the MNIST dataset"
      ],
      "metadata": {
        "id": "2U7mivEn31bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/drive/MyDrive/ML_dataSet/MNIST_DS/' #The folder where MNIST data will be downloaded and saved\n",
        "\n",
        "dataset = MNIST(root=root, download=True)\n",
        "test_dataset = MNIST(root=root, train=False)\n",
        "dataset = MNIST(root=root,train=True,transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "8OGUdHWFAlxb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor, label = dataset[0]\n",
        "print(img_tensor.shape,label)"
      ],
      "metadata": {
        "id": "UoTFRvy0BRNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset\\\n",
        "Here I have taken a split 50K as train and 10K as test\\\n",
        "The batch size here is 128, since SGD is being used as the optimizer\\\n",
        "*input_size* determines the input layer size\\\n",
        "*num_classes* is for categories, Mnist has multiple categories"
      ],
      "metadata": {
        "id": "jI3hrCtM4CQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds,test_ds = random_split(dataset,[50000,10000])\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_ds,batch_size,shuffle=True)\n",
        "test_loader = DataLoader(test_ds,batch_size)\n",
        "input_size = 28*28\n",
        "num_classes= 10"
      ],
      "metadata": {
        "id": "uMbA3hMLBjza"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTmodel(nn.Module):\n",
        "  def __init__(self,in_feature,out_feature,learning_rate,optimization_funtion,train_batches,test_batches,epochs=100):\n",
        "    super().__init__()\n",
        "    self.model = nn.Linear(in_feature,out_feature)\n",
        "    self.learning_rate = learning_rate\n",
        "    self.optimization_funtion = optimization_funtion\n",
        "    self.epochs = epochs\n",
        "    self.train_batches = train_batches\n",
        "    self.test_batches = test_batches\n",
        "\n",
        "  \"\"\"Forward method finds the probabilty of each image w.r.t each category and returns it\"\"\"\n",
        "  def forward(self,x):    \n",
        "    x = x.reshape(-1,784)\n",
        "    p = self.model(x)\n",
        "    return p\n",
        "  \n",
        "  \"\"\"Cross Entropy is generally used at a place where multiple classes are present, every input is in a form of minibatch and output is also a minibatch\"\"\"\n",
        "  def __training_step(self,batch):\n",
        "    loss=0\n",
        "    images,labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    return loss\n",
        "\n",
        "  def __validation_step(self,batch):\n",
        "    images, labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    acc = self.__accuracy(out,labels)\n",
        "    return {0:loss,1:acc}\n",
        "  \n",
        "  def __accuracy(self,out,label):\n",
        "    _,pred = torch.max(out,dim=1)\n",
        "    return torch.sum(label==pred).item() / len(pred)\n",
        "\n",
        "  def fit(self):\n",
        "    optimizer = self.optimization_funtion(self.model.parameters(),self.learning_rate)\n",
        "    for epoch in range(self.epochs):\n",
        "      for batch in self.train_batches:\n",
        "        loss = self.__training_step(batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "      if epoch%10==0:   #test how good the model is doing after every 10 epochs\n",
        "        loss=0\n",
        "        acc=0\n",
        "        for batch in self.test_batches:\n",
        "          o_p = self.__validation_step(batch)\n",
        "          loss += o_p[0]\n",
        "          acc += o_p[1]\n",
        "        loss=loss/len(self.test_batches)\n",
        "        acc =acc/len(self.test_batches)\n",
        "        print('Loss is {0:1.4f} and Accuracy {1:1.4f} of the model at epoch {2}'.format(loss,acc,epoch))\n",
        "        print(\"===================================================================================\")\n"
      ],
      "metadata": {
        "id": "BNERy-RLDrCs"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MM = MNISTmodel(in_feature=input_size,\n",
        "                out_feature=num_classes,\n",
        "                learning_rate=1e-3,\n",
        "                optimization_funtion=torch.optim.SGD,\n",
        "                train_batches = train_loader,\n",
        "                test_batches = test_loader)\n",
        "MM.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCkSAAmxmSDS",
        "outputId": "875b538e-adf9-47d1-e356-54a1cc180e1f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss is 1.9310 and Accuracy 0.6077 of the model at epoch 0\n",
            "===================================================================================\n",
            "Loss is 0.8493 and Accuracy 0.8381 of the model at epoch 10\n",
            "===================================================================================\n",
            "Loss is 0.6517 and Accuracy 0.8591 of the model at epoch 20\n",
            "===================================================================================\n",
            "Loss is 0.5672 and Accuracy 0.8681 of the model at epoch 30\n",
            "===================================================================================\n",
            "Loss is 0.5188 and Accuracy 0.8757 of the model at epoch 40\n",
            "===================================================================================\n",
            "Loss is 0.4867 and Accuracy 0.8800 of the model at epoch 50\n",
            "===================================================================================\n",
            "Loss is 0.4636 and Accuracy 0.8830 of the model at epoch 60\n",
            "===================================================================================\n",
            "Loss is 0.4459 and Accuracy 0.8859 of the model at epoch 70\n",
            "===================================================================================\n",
            "Loss is 0.4319 and Accuracy 0.8887 of the model at epoch 80\n",
            "===================================================================================\n",
            "Loss is 0.4205 and Accuracy 0.8915 of the model at epoch 90\n",
            "===================================================================================\n"
          ]
        }
      ]
    }
  ]
}